{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.script import *\n",
    "from pathlib import Path\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_docs(\n",
    "\tdir_comments: str,  # directory containing parquet dataframes\n",
    "\tmax_docs=None\n",
    "\t) -> pd.Series:\n",
    "\tfpaths = list(Path(dir_comments).glob('*.parquet'))\n",
    "\tdf = pd.read_parquet(fpaths, columns=['body'])\n",
    "\tprint('finished reading parquet files')\n",
    "\tif max_docs:\n",
    "\t\tdf = df.sample(max_docs)\n",
    "\tdocs = df['body'].str.split()\n",
    "\tprint('finished tokenizing')\n",
    "\treturn docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reading parquet files\n",
      "finished tokenizing\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "docs = get_docs('/Users/quirin/proj/getreddit/out/Coronavirus/', max_docs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Corpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "    def __init__(self, docs):\n",
    "        self.docs_clean = docs\n",
    "\n",
    "    def __iter__(self):\n",
    "        for doc in self.docs_clean:\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Word2VecLogger(gensim.models.callbacks.CallbackAny2Vec):\n",
    "    # Initialize any variables or attributes here\n",
    "    def __init__(self):\n",
    "        self.epoch = 0 # Keep track of the current epoch number\n",
    "\n",
    "    # Do something at the start of each epoch\n",
    "    def on_epoch_begin(self, model):\n",
    "        logging.info(f\"Epoch {self.epoch} started\")\n",
    "\n",
    "    # Do something at the end of each epoch\n",
    "    def on_epoch_end(self, model):\n",
    "        logging.info(f\"Epoch {self.epoch} finished\")\n",
    "        self.epoch += 1 # Increment the epoch number\n",
    "\n",
    "    # Do something at the start of each batch\n",
    "    def on_batch_begin(self, model):\n",
    "        pass # You can add your own code here\n",
    "\n",
    "    # Do something at the end of each batch\n",
    "    def on_batch_end(self, model, cumulative_stats):\n",
    "        # Get some statistics from cumulative_stats dictionary\n",
    "        total_examples = cumulative_stats['total_examples']\n",
    "        total_words = cumulative_stats['total_words']\n",
    "        job = cumulative_stats['job']\n",
    "        raw_words = cumulative_stats['raw_words']\n",
    "        effective_words = cumulative_stats['effective_words']\n",
    "\n",
    "        # Calculate and print some percentages using these statistics\n",
    "        percentage_sentences = (job[1] - job[0]) / total_examples * 100\n",
    "        percentage_words = raw_words / total_words * 100\n",
    "        percentage_effective_words = effective_words / raw_words * 100\n",
    "\n",
    "        logging.info(f\"Batch processed {percentage_sentences:.2f}% sentences and {percentage_words:.2f}% words\")\n",
    "        logging.info(f\"Batch used {percentage_effective_words:.2f}% words effectively for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_model(docs):\n",
    "    logger = Word2VecLogger()\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    model = Word2Vec(\n",
    "        docs,\n",
    "        workers=8,\n",
    "        min_count=5,\n",
    "        window=5,\n",
    "        epochs=5,\n",
    "        vector_size=300,\n",
    "        batch_words=10_000,\n",
    "        callbacks=[logger]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@call_parse\n",
    "def train_model_pipe(\n",
    "    dir_comments: str,  # Directory containing parquet dataframes\n",
    "    max_docs: int = None,  # Maximum number of parquet files to be processed\n",
    "    fp_model_out: str = None  # Save model to this file path\n",
    "    ) -> Word2Vec:\n",
    "    \"\"\"\n",
    "    Trains a word2vec model on the comments of a subreddit.\n",
    "    \"\"\"\n",
    "    docs = get_docs(dir_comments, max_docs)\n",
    "    corpus = Corpus(docs)\n",
    "    model = train_model(corpus)\n",
    "    if fp_model_out:\n",
    "        model.save(fp_model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reading parquet files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 11:01:21,137 : INFO : collecting all words and their counts\n",
      "2023-02-17 11:01:21,138 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-02-17 11:01:21,138 : INFO : collected 123 word types from a corpus of 168 raw words and 5 sentences\n",
      "2023-02-17 11:01:21,138 : INFO : Creating a fresh vocabulary\n",
      "2023-02-17 11:01:21,139 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 3 unique words (2.44% of original 123, drops 120)', 'datetime': '2023-02-17T11:01:21.139077', 'gensim': '4.3.0', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]', 'platform': 'macOS-13.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-17 11:01:21,139 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 18 word corpus (10.71% of original 168, drops 150)', 'datetime': '2023-02-17T11:01:21.139587', 'gensim': '4.3.0', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]', 'platform': 'macOS-13.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-17 11:01:21,139 : INFO : deleting the raw counts dictionary of 123 items\n",
      "2023-02-17 11:01:21,140 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2023-02-17 11:01:21,140 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1.0334733192202057 word corpus (5.7%% of prior 18)', 'datetime': '2023-02-17T11:01:21.140506', 'gensim': '4.3.0', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]', 'platform': 'macOS-13.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-17 11:01:21,140 : INFO : estimated required memory for 3 words and 300 dimensions: 8700 bytes\n",
      "2023-02-17 11:01:21,141 : INFO : resetting layer weights\n",
      "2023-02-17 11:01:21,141 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-02-17T11:01:21.141828', 'gensim': '4.3.0', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]', 'platform': 'macOS-13.1-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2023-02-17 11:01:21,142 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 3 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-17T11:01:21.142075', 'gensim': '4.3.0', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]', 'platform': 'macOS-13.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-02-17 11:01:21,142 : INFO : Epoch 0 started\n",
      "2023-02-17 11:01:21,145 : INFO : EPOCH 0: training on 168 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2023-02-17 11:01:21,146 : INFO : Epoch 0 finished\n",
      "2023-02-17 11:01:21,146 : INFO : Epoch 1 started\n",
      "2023-02-17 11:01:21,149 : INFO : EPOCH 1: training on 168 raw words (1 effective words) took 0.0s, 5105 effective words/s\n",
      "2023-02-17 11:01:21,149 : INFO : Epoch 1 finished\n",
      "2023-02-17 11:01:21,149 : INFO : Epoch 2 started\n",
      "2023-02-17 11:01:21,151 : INFO : EPOCH 2: training on 168 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2023-02-17 11:01:21,151 : INFO : Epoch 2 finished\n",
      "2023-02-17 11:01:21,152 : INFO : Epoch 3 started\n",
      "2023-02-17 11:01:21,154 : INFO : EPOCH 3: training on 168 raw words (2 effective words) took 0.0s, 19769 effective words/s\n",
      "2023-02-17 11:01:21,154 : INFO : Epoch 3 finished\n",
      "2023-02-17 11:01:21,154 : INFO : Epoch 4 started\n",
      "2023-02-17 11:01:21,156 : INFO : EPOCH 4: training on 168 raw words (1 effective words) took 0.0s, 2760 effective words/s\n",
      "2023-02-17 11:01:21,156 : INFO : Epoch 4 finished\n",
      "2023-02-17 11:01:21,156 : INFO : Word2Vec lifecycle event {'msg': 'training on 840 raw words (4 effective words) took 0.0s, 272 effective words/s', 'datetime': '2023-02-17T11:01:21.156988', 'gensim': '4.3.0', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]', 'platform': 'macOS-13.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-02-17 11:01:21,157 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=3, vector_size=300, alpha=0.025>', 'datetime': '2023-02-17T11:01:21.157166', 'gensim': '4.3.0', 'python': '3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]', 'platform': 'macOS-13.1-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tokenizing\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "model = train_model_pipe('conspiracy', '/Users/quirin/proj/getreddit/out/conspiracy', max_docs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
